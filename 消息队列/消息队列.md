###为啥要使用MQ
#### MQ的优点
1. 异步
2. 解耦
3. 削峰填谷
#### MQ的缺点
1. 系统复杂的提高
2. 系统可用性降低
3. 数据一致性问题

### 如何保证消息队列的高可用性
kafka由多个broker组成，一个broker为一个节点，一个topic包括多个partition，每个partition可以存在于多个broker中；

这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。

每个partition有一个leader和多个follower，生产者、消费者读写与leader打交道，leader负责同步数据到follower中，如果leader挂了，由follower选举产生新的leader；

以此保证了kafka的高可用性HA；

### 如何保证消息不被重复消费（幂等性问题）
Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

如果kafka没来得及提交offset就被异常关闭，那么如何保证幂等性；

如果消费方是数据库，可以根据主键进行查重
如果是redis，redis的set操作天然幂等性；
如果是其他的，可以再消息中加入唯一id，根据该唯一id结合redis来实现幂等性，不存在插入，存在则更新该redis；

### 如何保证消息不会丢失
kafka 
消费端丢失消息情况：

唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边自动提交了 offset，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。

kafka丢失消息的情况：

这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊

需要对kafka设置以下四个参数：
1. 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
2. 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
3. 在 producer 端设置 acks=all ：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
4. 在 producer 端设置 retries=MAX （很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。

#### 如何保证消息的顺序
kafka 如果一个topic，有三个partition。生产者在写的时候，可以指定一个key，比如订单系统中id作为key，那么这个订单相关的消息数据，就会被分发在同一个partition中，
而且数据之间是有顺序的；

消费者按照顺序从partiton中读取数据也是有顺序的，但是这样处理起来吞吐量会比较低，如果使用多线程去消费处理，就会出现错乱；

解决方法：
写N个内存queue，具有相同key的数据都到同一个内存queue；然后N个线程，每一个线程消费一个内存queue即可保证顺序性；

#### 大量消息在mq中积压
也就是消费者出现了消费速度慢的问题：

一般这种情况紧急扩容：
1. 先修复consumer的问题，确保其恢复消费速度，然后将现有的consumer停掉；
2. 新建一个topic，partition是原来的10倍，临时建立原先10倍的queue数量；
3. 然后写一个临时的分发数据的consumer程序，将积压的数据直接轮询写入临时建立好的10倍queue中；
4. 临时征调10倍的机器来部署consumer，每一批consumer消费一个临时的queue；
5. 快速消费完积压数据后，回复原有框架；或根据问题扩容现有框架；

#### 消息过期问题
根据消息的重要性进行丢弃，或者由于消息积压造成的消息过期丢失；
等待消息的高峰期过去，根据业务逻辑将原有丢弃数据补回来；

#### mq积压导致磁盘爆满
1. 提高消费的并行度，增加consumer的数量
2. 批量方式的消费；
3. 提过非重要的消息，后续补数据；
4. 优化每条消息的消费过程；